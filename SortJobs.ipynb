{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('ResumeAnalysis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "26e0d223c6b652543b86b5d5c5ffe1a4b96a31867acf239f8943a157f7dfbe3b"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from nltk import *\n",
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures, TrigramAssocMeasures\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import clear_output\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_jobs(df, posting_number):\n",
    "    \"\"\"Prompt user for response, use the response to place posting_number into an array\"\"\"\n",
    "    job_status = input('Is this a job you would want to apply to? (y/n/u/o) \\n(u is yes but underqualified, o is none of the above.)')\n",
    "    if job_status.lower() in ['yes', 'yeah', 'y']:\n",
    "        yes.append(posting_number)\n",
    "        print(f\"https://www.monster.com/jobs/search/?q=Data-Scientist&jobid={df.jobid[posting_number]}\")\n",
    "    elif job_status.lower() in ['no', 'nah', 'n']:\n",
    "        no.append(posting_number)\n",
    "    elif job_status.lower() in ['maybe', 'm', 'other', 'o']:\n",
    "        other.append(posting_number)\n",
    "    elif job_status.lower() in ['underqualified', 'u']:\n",
    "        underqualified.append(posting_number)\n",
    "    elif job_status.lower() == 'ty':\n",
    "        yes_test.append(posting_number)\n",
    "    elif job_status.lower() == 'tn':\n",
    "        no_test.append(posting_number)\n",
    "\n",
    "def job_post_info(posting_number: int, df = df, n_results_per: int = 10, sorting: bool = True):\n",
    "    '''\n",
    "        Print important bigrams and trigrams and the job description\n",
    "        0. Assemble stopword set\n",
    "        1. Tokenize Sentences\n",
    "        2. Remove sentences with particular words \n",
    "        3. Tokenize words from remaining sentences\n",
    "        4. Remove stopwords\n",
    "        5. Print collection of important bigrams and trigrams from remaining words\n",
    "        6. Print the entire job description\n",
    "        7. If we are sorting:\n",
    "            7a. Prompt user to determine whether it's a yes, a no, a job the user is \n",
    "                underqualified for, or other\n",
    "            7b. Depending on user's response append post index to appropriate list\n",
    "    ''' \n",
    "    stopset = set(stopwords.words('english') + word_tokenize(df['company'][posting_number].lower()))\n",
    "    sentences = sent_tokenize(df.description[posting_number])\n",
    "    sentences = [sentence for sentence in sentences if not [p for p in ['equal opportunity', 'not discriminate', 'diversity', 'affirmative action', 'gender', 'eoe'] if p  in sentence.lower()]]\n",
    "    words = [word for words in sentences for word in word_tokenize(words.lower()) if word not in stopset]\n",
    "    words = [word for word in words if (word.isalpha() or word.isnumeric()) and (len(word) < 2 or len(word) > 3)]\n",
    "    bcf = BigramCollocationFinder.from_words(words)\n",
    "    tcf = TrigramCollocationFinder.from_words(words)\n",
    "    # Print company and job title\n",
    "    print(df.company[posting_number])\n",
    "    print(df.title[posting_number])\n",
    "    print(\"Location:\", df.location[posting_number])\n",
    "    print()\n",
    "    # print bigrams\n",
    "    print('Bigrams')\n",
    "    print(set(bcf.nbest(BigramAssocMeasures.likelihood_ratio, n_results_per) + bcf.nbest(BigramAssocMeasures.raw_freq, n_results_per) + bcf.nbest(BigramAssocMeasures.chi_sq, n_results_per)))\n",
    "    print()\n",
    "    # Print Trigrams\n",
    "    print('Trigrams')\n",
    "    print(set(tcf.nbest(TrigramAssocMeasures.likelihood_ratio, n_results_per) + tcf.nbest(TrigramAssocMeasures.raw_freq, n_results_per) + tcf.nbest(TrigramAssocMeasures.chi_sq, n_results_per)))\n",
    "    print()\n",
    "    print(df.description[posting_number])\n",
    "    # If we are sorting them to train an algo\n",
    "    if sorting:\n",
    "        # If we are sorting through them\n",
    "        sort_jobs(df, posting_number)\n"
   ]
  },
  {
   "source": [
    "## Initialize empty job index containers.\n",
    "These take the index position of the jobs in the data frame. Later they are used to form yes, no, and undequalified labels to train an algorithm."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################\n",
    "#                                                                #\n",
    "# MAKE SURE PREVIOUS DATA HAS BEEN WRITTEN BEFORE CLEARING !!!!! #\n",
    "#                                                                #\n",
    "##################################################################\n",
    "yes = []\n",
    "no = []\n",
    "underqualified = []\n",
    "other = []"
   ]
  },
  {
   "source": [
    "## Import job post data frame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_csv('data/2020-12-14_jobsmonster.tsv', sep=\"\\t\")\n",
    "df1 = df_0\n",
    "df1.columns = df1.columns.str.lower()\n",
    "df1.description = df1.description.str.replace('A/R', 'AR')\n",
    "for col in df1.columns:\n",
    "    if col != 'posted':\n",
    "        df1[col] = df1[col].str.replace('\\n', ' ').str.replace('\\r', ' ').str.replace('/', ' ').str.replace(',', ' ')\n",
    "\n",
    "df1.description = df1.description.str.replace(r\"([a-z])([A-Z])\", r\"\\1 \\.\\2\").str.replace(r' \\\\.', '')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.drop(yes)\n",
    "df = df.drop(no)\n",
    "df = df.drop(other)\n",
    "df = df.drop(underqualified)\n",
    "df[\n",
    "  # df.description.str.lower().str.contains('scrap')\n",
    "    # ~df.salary.str.lower().str.contains('no')\n",
    "    # df.description.str.lower().str.contains('math')\n",
    "    #  (\n",
    "    #     df.description.str.lower().str.contains('python') \n",
    "    #    | df.description.str.lower().str.contains(' r ')\n",
    "    #  )\n",
    "    #  df.description.str.lower().str.contains('sql')\n",
    "    # & df.description.str.lower().str.contains('')\n",
    "    # & ~df.company.str.lower().str.contains('jpm')\n",
    "     (\n",
    "        df.title.str.lower().str.contains('assoc') \n",
    "      | df.title.str.lower().str.contains('junior')\n",
    "      | df.title.str.lower().str.contains('jr')\n",
    "      | df.title.str.lower().str.contains('entry')\n",
    "      )\n",
    "    & ~(\n",
    "        df.title.str.lower().str.contains('lead')\n",
    "      | df.title.str.lower().str.contains('manager')\n",
    "      | df.title.str.lower().str.contains('vp')\n",
    "      | df.title.str.lower().str.contains('vice')\n",
    "      | df.title.str.lower().str.contains('senior')\n",
    "      | df.title.str.lower().str.contains('sr')\n",
    "      | df.title.str.lower().str.contains('principal')\n",
    "      )\n",
    "    # & ~(\n",
    "    #   df.location.str.contains('DE')\n",
    "    #   | df.location.str.contains('NH')\n",
    "    #   | df.location.str.contains('PA')\n",
    "    # )\n",
    "    & (df['posted'] < 22)\n",
    "].sort_values('posted')\n",
    "# df1.sort_values('posted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "If we put together a list of posts to go through:\n",
    "    1. Clear previous output\n",
    "    2. Show the post info and sort the job\n",
    "\"\"\"\n",
    "for post in sl:\n",
    "    clear_output()\n",
    "    job_post_info(post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many do we have?\n",
    "print(\"yes:\", len(yes))\n",
    "print(\"no:\", len(no))\n",
    "print(\"underqualified:\", len(underqualified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When finished sorting, uncomment the below and save the classified data\n",
    "# our_columns = ['company', 'title', 'description']\n",
    "# df_0.loc[yes, our_columns].to_csv('data/yes.tsv', sep='\\t', index=False, header=False, mode = 'a')\n",
    "# df_0.loc[no, our_columns].to_csv('data/no.tsv', sep='\\t', index=False, header=False, mode = 'a')\n",
    "# df_0.loc[underqualified, our_columns].to_csv('data/underqualified.tsv', sep='\\t', index=False, header=False, mode='a')"
   ]
  }
 ]
}